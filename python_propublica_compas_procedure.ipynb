{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwaldenphd/AntConc-tutorial/blob/master/python_propublica_compas_procedure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw8omBTNbwV5"
      },
      "source": [
        "# ProPublica COMPAS Lab\n",
        "\n",
        "<a href=\"http://creativecommons.org/licenses/by-nc/4.0/\" rel=\"license\"><img style=\"border-width: 0;\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" alt=\"Creative Commons License\" /></a>\n",
        "This tutorial is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc/4.0/\" rel=\"license\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfNDlzd2bxXR"
      },
      "source": [
        "## Acknowledgements\n",
        "\n",
        "This lab is based on the research and technical documentation for *ProPublica*'s 2016 \"Machine Bias\" article.\n",
        "- Julia Angwin, Jeff Larson, Surya Mtatu, and Lauren Kirchner, “[Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)” *ProPublica* (23 May 2016). \n",
        "- Jeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin, “[How We Analyzed the COMPAS Recidivism Algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)” *ProPublica* (23 May 2016).\n",
        "- [Link to Google Drive folder that contains the following items:](https://drive.google.com/drive/folders/1-by_FJK2wi86flevOi2WKmomE6wL93yB?usp=sharing)\n",
        "  * Northpointe document collection gathered by ProPublica team\n",
        "  * Sentencing reports that include risk assessment, gathered by ProPublica team\n",
        "- [GitHub repository with data files and Jupyter notebook for ProPublica analysis of COMPAS risk scores](https://github.com/propublica/compas-analysis)\n",
        "\n",
        "The lab is also adapted from a lab developed by [Lauren F. Klein](https://lklein.com/) for the Spring 2020 Emory University course [QTM 490 \"Feminist Data Science\"](https://github.com/laurenfklein/feminist-data-science).\n",
        "- [Lab activity resources (data + Jupyter Notebook)](https://github.com/laurenfklein/feminist-data-science/tree/master/notebooks/lab3-compas)\n",
        "\n",
        "Klein's lab is based on an exercise by Bucknell University Assistant Professor of Computer Science [Darakhshan Mir](http://eg.bucknell.edu/~djm056/)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "In 2016, a *ProPublica* investigative journalism team including published \"Machine Bias,\" an incisive look at the COMPAS risk prediction system used in the criminal justice system. In addition to the main story that emphasizes the human toll of a racially-biased system, the *ProPublica* team published a detailed methodology, data, and technical documentation for the story.\n",
        "\n",
        "This lab is based on that work."
      ],
      "metadata": {
        "id": "dotbGE9ZqL20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Materials"
      ],
      "metadata": {
        "id": "COiYCWLmqRzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Template\n",
        "- [Jupyter Notebook](https://colab.research.google.com/drive/1e3ZeCyHOjauNVEW5U0NPq-_exceAKYmy?usp=sharing)\n",
        "- [Google Doc](https://docs.google.com/document/d/1SzcEiEbTTTyiPDygGP4Bw0OWOwEsN0Y5x7RHfJCP-Vw/copy)"
      ],
      "metadata": {
        "id": "WwPa2d8pqREn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Files\n",
        "\n",
        "We'll need the `truth_tables.py` file to run some of the calculations later on in this lab.\n",
        "- [Link to download](https://drive.google.com/file/d/1hH8TfJ1ADcXs7WnrVrzTNPzaoGxeN4qH/view?usp=sharing) from Google Drive\n",
        "- [Link to download from GitHub](https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/truth_tables.py)\n"
      ],
      "metadata": {
        "id": "_FvzUyr1qUAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to download the file within your Python IDE\n",
        "import json, requests, urllib, urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/truth_tables.py\", \"truth_tables.py\")"
      ],
      "metadata": {
        "id": "EBp-lJIIqXXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "We'll also be using four data files.\n",
        "- `compas-scores-two-years-violent.csv`\n",
        "  * [Google Drive](https://drive.google.com/file/d/1ONM0NwwCLxeIF0Z23jpyHpBFdQxclGcR/view?usp=sharing)\n",
        "  * [GitHub URL](https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/compas-scores-two-years-violent.csv)\n",
        "- `compas-scores-two-years.csv`\n",
        "  * [Google Drive](https://drive.google.com/file/d/1KgZomaF2Jbob9sW5zrhQs8NcnEd5h2hG/view?usp=sharing)\n",
        "  * [GitHub URL](https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/compas-scores-two-years.csv)\n",
        "- `cox-parsed.csv`\n",
        "  * [Google Drive](https://drive.google.com/file/d/1uGr-5xnRPdcZKHtgCY6qiSDguPjNLzoL/view?usp=sharing)\n",
        "  * [GitHub URL](https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-parsed.csv)\n",
        "- `cox-violent-parsed.csv`\n",
        "  * [Google Drive](https://drive.google.com/file/d/1ewAjZObRNCcx55w6Z4WtbphlIRZdy_X3/view?usp=sharing)\n",
        "  * [GitHub URL](https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-violent-parsed.csv)\n",
        "\n",
        "[Link to download all files for this lab from Google Drive as a .zip](https://drive.google.com/file/d/10ntNzhF7c7b-4G1ifeZkM5ThjFeKH-Ja/view?usp=sharing)."
      ],
      "metadata": {
        "id": "XEw2pH8KqaHN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBnv2ks5bz7A"
      },
      "source": [
        "# The Story\n",
        "\n",
        "Read: Julia Angwin, Jeff Larson, Surya Mtatu, and Lauren Kirchner, “[Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)” *ProPublica* (23 May 2016). \n",
        "\n",
        "Discussion questions: \n",
        "- What stood out to you from the story? \n",
        "  * Where and how do we see race and surveillance at work?\n",
        "- From reading the story, what are you able to tell about how the authors analyzed the technology system?\n",
        "- How do the authors describe the design and functionality of the technology system?\n",
        "- Other comments, questions, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlUpawE8b1F4"
      },
      "source": [
        "# The Methodology\n",
        "\n",
        "Read: Jeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin, “[How We Analyzed the COMPAS Recidivism Algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)” *ProPublica* (23 May 2016).\n",
        "\n",
        "Discussion questions:\n",
        "- What were the goals or central questions for the study?\n",
        "- Wat data sources did they draw on (and why)?\n",
        "- How did they approach analyzing the algorithm?\n",
        "  * Specific questions\n",
        "  * Statistical methods\n",
        "  * Visualizations/calculations\n",
        "- What conclusions do the authors draw from the analysis?\n",
        "  * Connections we can make with race and surveillance?\n",
        "- Other comments, questions, observations, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bqXwg5Jb23r"
      },
      "source": [
        "# Data Sources\n",
        "\n",
        "Explore:\n",
        "- [Link to Google Drive folder that contains](https://drive.google.com/drive/folders/1-by_FJK2wi86flevOi2WKmomE6wL93yB?usp=sharing)\n",
        "  * Northpointe document collection gathered by ProPublica team\n",
        "  * Sentencing reports that include risk assessment, gathered by ProPublica team\n",
        "- [GitHub repository with data files and Jupyter notebook for ProPublica analysis of COMPAS risk scores](https://github.com/propublica/compas-analysis)\n",
        "\n",
        "Discussion questions:\n",
        "- What data sources did the ProPublica team draw on?\n",
        "  * Who was involved in collecting this data/information?\n",
        "  * Why was this data/information originally collected? Or what was the original purpose for data collection?\n",
        "- Where do we see power at work in this data/information? \n",
        "  * *A lot of directions you could go with this question- how/why the data was collected, categories or classification systems used, etc.*\n",
        "- What data points (or discrete pieces of information) are represented?\n",
        "- How did the authors organize or filter the data? What transformations happened to get from the original data source to the data structure used in the analysis?\n",
        "- Other comments, questions, observations, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithm Audit"
      ],
      "metadata": {
        "id": "tOVhWvz0q4LS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup & Environment\n",
        "\n",
        "Throughout this lab, we'll be using RStudio syntax within Python to facilitate easier exploratory data analysis and data wrangling.\n",
        "- NOTE: If you're working through the lab in RStudio, you'll be using Python syntax from within RStudio.\n",
        "\n",
        "We can do this using the `rpy2` package.\n",
        "- [Click here for more information and documentation on the `rpy2` package](https://pypi.org/project/rpy2/)\n"
      ],
      "metadata": {
        "id": "8tIDUwJpq5vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### If Using Jupyter Notebook/Jupyter Lab (Anaconda)\n",
        "\n",
        "First step is to create a new Anaconda environment. This process may take some time.\n",
        "- Launch the Anaconda Navigator.\n",
        "- Click on the \"Environments\" option on the left-hand menu.\n",
        "- Click the \"Create\" icon to create a new environment.\n",
        "- In the popup, label this new environment and make sure BOTH Python and R are selected. You may need to select `r` from the dropdown menu.\n",
        "- Click the \"Create\" button to create this environment.\n",
        "\n",
        "\n",
        "Once the new environment with Python and R is ready to go, click on the arrow next to the environment name and select the option to \"Open with Jupyter Lab.\"  Now we have a Jupyter Notebook environment that can run both Python and RStudio.\n",
        "\n",
        "For more details on this process: [\"Using the R programming language in Jupyter Notebook\"](https://docs.anaconda.com/anaconda/navigator/tutorials/r-lang/) *Anaconda*"
      ],
      "metadata": {
        "id": "i2rjxdYJq7hd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Everyone\n",
        "\n",
        "Our next step is to install the `rpy2` package."
      ],
      "metadata": {
        "id": "8hjnVgEjq8qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install a pip package in the current Jupyter kernel\n",
        "import sys\n",
        "!{sys.executable} -m pip install rpy2==3.5.1"
      ],
      "metadata": {
        "id": "fBwy7Dbqq9uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can import the `rpy2` module into Python and set up what is called a `magic command` to run RStudio syntax from within our Python Jupyter Notebook."
      ],
      "metadata": {
        "id": "uBOfQgyhq-ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up rpy2 magic command\n",
        "%load_ext rpy2.ipython\n",
        "\n",
        "# filter rstudio warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "C2RVXTIaq_N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, anytime we want to run RStudio code, we can start a code cell with the `%%R` magic command.\n",
        "- Folks using Anaconda may run into error messages when running the previous block of code. If needed, run the code below and replace the file path with the anaconda path to R from your local computer."
      ],
      "metadata": {
        "id": "7tYqb2_orEkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for anaconda users\n",
        "import os\n",
        "os.environ['R_HOME'] = '/Users/<your user>/anaconda3/envs/<env name>/lib/R'"
      ],
      "metadata": {
        "id": "hg9XINMvrFnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A couple more R packages to load before we start bringing in the data."
      ],
      "metadata": {
        "id": "U02qgpolrIJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# load dplyr package for data wrangling\n",
        "library(dplyr)\n",
        "\n",
        "# load ggplot package for visualization\n",
        "library(ggplot2)"
      ],
      "metadata": {
        "id": "MaNLG7r_rJBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"`dplyr` is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges:\n",
        "  * `mutate()` adds new variables that are functions of existing variables\n",
        "  * `select()` picks variables based on their names.\n",
        "  * `filter()` picks cases based on their values.\n",
        "  * `summarise()` reduces multiple values down to a single summary.\n",
        "  * `arrange()` changes the ordering of the rows.\n",
        "\n",
        "These all combine naturally with `group_by()` which allows you to perform any operation “by group”. You can learn more about them in [`vignette(\"dplyr\")`](https://dplyr.tidyverse.org/articles/dplyr.html). As well as these single-table verbs, dplyr also provides a variety of two-table verbs, which you can learn about in [`vignette(\"two-table\")`](https://dplyr.tidyverse.org/articles/two-table.html).” [Source: [dplyr.tidyverse.org](https://dplyr.tidyverse.org/)]\n",
        "- More dplyr documentation: [cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html)\n",
        "- For more on the conceptual foundations for data transformation in `R`: [Chapter 5, \"Data Transformation\"](https://r4ds.had.co.nz/transform.html) in Hadley Wickham and Garrett Grolemund, [*R for Data Science: Visualize, Model, Transform, Tidy, and Import Data*](https://r4ds.had.co.nz/index.html) (O'Reilly, 2017).\n",
        "\n",
        "“R has several systems for making graphs, but `ggplot2` is one of the most elegant and most versatile. ggplot2 implements the grammar of graphics, a coherent system for describing and building graphs. With ggplot2, you can do more faster by learning one system and applying it in many places.” [[Chapter 3 “Data Visualization”](https://r4ds.had.co.nz/data-visualisation.html) in Garrett Grolemund and Hadley Wickham, *R for Data Science*]\n",
        "\n",
        "“`ggplot2` is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details...It’s hard to succinctly describe how ggplot2 works because it embodies a deep philosophy of visualisation. However, in most cases you start with ggplot(), supply a dataset and aesthetic mapping (with aes()). You then add on layers (like geom_point() or geom_histogram()), scales (like scale_colour_brewer()), faceting specifications (like facet_wrap()) and coordinate systems (like coord_flip()).” [[ggplot2.tidyverse.org](https://ggplot2.tidyverse.org/)]\n",
        "\n",
        "We're also going to install and load a few Python packages to have on hand for later in the lab.\n"
      ],
      "metadata": {
        "id": "ACA9scUkrw9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install matplotlib\n",
        "import sys\n",
        "!{sys.executable} -m pip install matplotlib"
      ],
      "metadata": {
        "id": "UwJlilKwrzWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load all the things!\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import pylab\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ohv_c2VUr0lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Wrangling"
      ],
      "metadata": {
        "id": "KgdnxaOMr1lQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading\n",
        "\n",
        "We're going to work with two datasets in this lab, both developed and published by the *ProPublica* team. In `compas-scores-two-years.csv`, the *ProPublica* team selected fields for severity of charge, number of priors, demographics, age, sex, compas scores, and whether each person was accused of a crime within two years. We can see we have 52 columns/fields, and 7,214 rows/records in this dataset.\n",
        "\n",
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "CG14CKWnr3jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "# load data from CSV file using R dataframe syntax\n",
        "# compas_two_year_scores <- read.csv(\"compas-scores-two-years.csv\")\n",
        "\n",
        "# load data from URL using R dataframe syntax\n",
        "compas_two_year_scores <- read.csv(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/compas-scores-two-years.csv\")\n",
        "\n",
        "# show data dimensions\n",
        "nrow(compas_two_year_scores)"
      ],
      "metadata": {
        "id": "LdXQz6P0s3hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python Syntax**\n",
        "\n",
        "We can also express these steps programatically in Python using `pandas`:"
      ],
      "metadata": {
        "id": "l29oND2Ls83n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data from file\n",
        "# compas_two_year_scores = pd.read_csv('compas-scores-two-years.csv', index_col=0)\n",
        "\n",
        "# load data from url\n",
        "compas_two_year_scores = pd.read_csv(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/compas-scores-two-years.csv\", index_col = 0)\n",
        "\n",
        "# show data shape\n",
        "compas_two_year_scores.shape"
      ],
      "metadata": {
        "id": "l0EMiY0xs-Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the first five rows of the dataset\n",
        "pd.options.display.max_columns = None # have to do this otherwise it limits the number of cols shown\n",
        "\n",
        "# show first five rows\n",
        "compas_two_year_scores.head()"
      ],
      "metadata": {
        "id": "F5s9xZrCs_QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering\n",
        "\n",
        "Not all of the rows are useable for the first round of analysis. The *ProPublica* team determined a number of criteria for removing missing or unusable data. \n",
        "\n",
        "These criteria are listed below:\n",
        "- If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
        "- We coded the recidivist flag -- `is_recid` -- to be -1 if we could not find a compas case at all.\n",
        "- In a similar vein, ordinary traffic offenses -- those with a `c_charge_degree` of 'O' -- will not result in Jail time are removed (only two of them).\n",
        "- We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\n",
        "\n",
        "To filter the data using these criteria...\n",
        "\n",
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "3iEjc8pctAeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# create new dataframe using filtering criteria\n",
        "df <- dplyr::select(compas_two_year_scores, age, c_charge_degree, race, age_cat, score_text, sex, priors_count, days_b_screening_arrest, decile_score, is_recid, two_year_recid, c_jail_in, c_jail_out) %>% \n",
        "        filter(days_b_screening_arrest <= 30) %>%\n",
        "        filter(days_b_screening_arrest >= -30) %>%\n",
        "        filter(is_recid != -1) %>%\n",
        "        filter(c_charge_degree != \"O\") %>%\n",
        "        filter(score_text != 'N/A')\n",
        "\n",
        "# show updated dataframe\n",
        "nrow(df)"
      ],
      "metadata": {
        "id": "llDmxAnTtB9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python Pandas Syntax**\n",
        "\n",
        "To run that filtering operation in Python, first we'll filter out those which do not have a COMPAS-scored case, as indicated by the recidivist flag `is_recid` set at -1."
      ],
      "metadata": {
        "id": "-5qcWHT_tEj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter data\n",
        "filterData = compas_two_year_scores[(compas_two_year_scores['is_recid'] != -1)]\n",
        "\n",
        "# show updated data shape\n",
        "filterData.shape"
      ],
      "metadata": {
        "id": "JqPNmCjotFcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More Filtering\n",
        "\n",
        "Within the cases with a COMPAS score, we also need to check to see if we have the right offense. So if the charge date of a defendant's COMPAS-scored crime was not within 30 days from when the person was arrested, it's best to assume that we do not have the right offense, and remove that row. We will filter out rows where **days_b_screening_arrest** is over 30 or under -30:\n",
        "\n",
        "**Python Pandas Syntax**"
      ],
      "metadata": {
        "id": "4jsRe6fItGo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter data\n",
        "filterData = compas_two_year_scores[(compas_two_year_scores['days_b_screening_arrest'] <= 30) & (compas_two_year_scores['days_b_screening_arrest'] >= -30)]\n",
        "\n",
        "# show updated data\n",
        "filterData.shape"
      ],
      "metadata": {
        "id": "KXBC54uGtHbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of both filtering processes should be the same: 52 columns or fields, and 6172 observations or rows/records.\n",
        "\n",
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "oX-rsgwytIq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unpacking Risk Scores\n",
        "\n",
        "Higher COMPAS scores are slightly correlated with a longer length of stay. \n",
        "\n",
        "**RStudio Syntax**\n"
      ],
      "metadata": {
        "id": "7Y8DFleRtJb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# select length of stay\n",
        "df$length_of_stay <- as.numeric(as.Date(df$c_jail_out) - as.Date(df$c_jail_in))\n",
        "\n",
        "# show correlation\n",
        "cor(df$length_of_stay, df$decile_score)"
      ],
      "metadata": {
        "id": "A39NDKX3tKkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After filtering we have the following demographic breakdown:\n",
        "\n",
        "#### By Age\n",
        "\n",
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "kM7pMD38tMwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# summary of age range represented in the dataset\n",
        "summary(df$age_cat)"
      ],
      "metadata": {
        "id": "mgPwqg9KtNwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python Pandas Syntax**"
      ],
      "metadata": {
        "id": "_yrAPNNKtOh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python syntax for age summary\n",
        "filterData.age_cat.value_counts()"
      ],
      "metadata": {
        "id": "fOez9zBNtPrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### By Race\n",
        "\n",
        "**Rstudio Syntax**"
      ],
      "metadata": {
        "id": "GcTwvBCctRFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# summary of race/ethnicity information represented in the dataset\n",
        "summary(df$race)"
      ],
      "metadata": {
        "id": "n_PTDrqQtR5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python Pandas Syntax**"
      ],
      "metadata": {
        "id": "AVS-mV4StS5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# race/ethnicity summary\n",
        "filterData.race.value_counts()"
      ],
      "metadata": {
        "id": "Fqn_ukVXtTrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show percentages by race/ethnicity\n",
        "print(\"Black defendants: %.2f%%\" %            (3175 / 6172 * 100))\n",
        "print(\"White defendants: %.2f%%\" %            (2103 / 6172 * 100))\n",
        "print(\"Hispanic defendants: %.2f%%\" %         (509  / 6172 * 100))\n",
        "print(\"Asian defendants: %.2f%%\" %            (31   / 6172 * 100))\n",
        "print(\"Native American defendants: %.2f%%\" %  (11   / 6172 * 100))"
      ],
      "metadata": {
        "id": "wYm2CWO_tVjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### By Risk Score\n",
        "\n",
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "0ufRmwRitWt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# summary of risk scores\n",
        "summary(df$score_text)"
      ],
      "metadata": {
        "id": "iNozupk3tXy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# cross tab summary of data by race/ethnicity and gender\n",
        "xtabs(~ sex + race, data=df)"
      ],
      "metadata": {
        "id": "pDxExoPFtY8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python Pandas Syntax**"
      ],
      "metadata": {
        "id": "y5_xEz4Yta2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# risk score summary\n",
        "filterData.score_text.value_counts()"
      ],
      "metadata": {
        "id": "eK-OSVG-tZ6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross tabs for recidivsm rates by race\n",
        "pd.crosstab(filterData.sex, filterData.race)"
      ],
      "metadata": {
        "id": "ffKCKgkUtdIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### By Gender\n",
        "\n",
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "DpDQh2jFteCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# summary of data by gender\n",
        "summary(df$sex)"
      ],
      "metadata": {
        "id": "5_1IN9cKtfLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python Pandas Syntax**"
      ],
      "metadata": {
        "id": "1JZiUQhntglR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gender breakdown\n",
        "filterData.sex.value_counts()"
      ],
      "metadata": {
        "id": "TK_yoqv_tiW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# percentages by gender\n",
        "print(\"Men: %.2f%%\" %   (4997 / 6172 * 100))\n",
        "print(\"Women: %.2f%%\" % (1175 / 6172 * 100))"
      ],
      "metadata": {
        "id": "KcjIUfCCtjqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### By Recidivism Rate\n",
        "\n",
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "J24KDAxUtlHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# number of rows where two_year_recid = 1\n",
        "nrow(filter(df, two_year_recid == 1))"
      ],
      "metadata": {
        "id": "QBfESVTLtl7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# percentage of rows where two_year_recid = 2\n",
        "nrow(filter(df, two_year_recid == 1)) / nrow(df) * 100"
      ],
      "metadata": {
        "id": "O5HXha0FtnTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Risk Scores\n",
        "\n",
        "Judges are often presented with two sets of scores from the Compas system -- one that classifies people into High, Medium and Low risk, and a corresponding decile score. *ProPublica*'s analysis found a clear downward trend in the decile scores as those scores increase for white defendants.\n",
        "\n",
        "**Calculating decile risk scores by race, using RStudio syntax**"
      ],
      "metadata": {
        "id": "3wX2pduStyT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# create bar chart with decile risk scores for Black defendants\n",
        "pblack <- ggplot(data=filter(df, race ==\"African-American\"), aes(ordered(decile_score))) + \n",
        "          geom_bar() + xlab(\"Decile Score\") +\n",
        "          ylim(0, 650) + ggtitle(\"Black Defendant's Decile Scores\")\n",
        "\n",
        "# create bar chart with decile risk scores for white defendants\n",
        "pwhite <- ggplot(data=filter(df, race ==\"Caucasian\"), aes(ordered(decile_score))) + \n",
        "          geom_bar() + xlab(\"Decile Score\") +\n",
        "          ylim(0, 650) + ggtitle(\"White Defendant's Decile Scores\")\n",
        "\n",
        "# show first bar chart\n",
        "show(pblack)\n",
        "\n",
        "# show second bar chart\n",
        "show(pwhite)"
      ],
      "metadata": {
        "id": "G_a8BocTt1AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# cross tab data by race and decile score\n",
        "xtabs(~ decile_score + race, data=df)"
      ],
      "metadata": {
        "id": "_q9eSeNnt2dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating decile risk scores by race, using Python Pandas syntax**"
      ],
      "metadata": {
        "id": "AI7c3mnot3Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross tabs by race/ethnicity\n",
        "scores_by_race = pd.crosstab(filterData.race, filterData.decile_score)\n",
        "\n",
        "# show scores\n",
        "scores_by_race"
      ],
      "metadata": {
        "id": "Xv6JKrGwt4DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating decile risk scores by race, using Python Pandas syntax**"
      ],
      "metadata": {
        "id": "XJCCGh1guHXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross tabs by race/ethnicity\n",
        "scores_by_race = pd.crosstab(filterData.race, filterData.decile_score)\n",
        "\n",
        "# show scores\n",
        "scores_by_race"
      ],
      "metadata": {
        "id": "ECKKYSIFuIH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# another visualization with the decile scores disaggregated by race/ethnicity\n",
        "\n",
        "# create labels\n",
        "labels = list(scores_by_race.columns)\n",
        "\n",
        "# list with scores by race\n",
        "aa_scores = list(scores_by_race.loc[\"African-American\"])\n",
        "c_scores = list(scores_by_race.loc[\"Caucasian\"])\n",
        "\n",
        "# arrange labels and set width\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "# generate plot\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, aa_scores, width, label='African-American')\n",
        "rects2 = ax.bar(x + width/2, c_scores, width, label='Caucasian')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Scores by decile and race')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "# function for placing labels\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "# run label placing functions\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "# update figure layout\n",
        "fig.tight_layout()\n",
        "\n",
        "# show figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bw-7o_AquKSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Racial Bias in COMPAS\n",
        "\n",
        "These visualizations suggest that *something* is going on. But in order to test our intution that there is a significant difference in COMPAS scores across different racial categories, we need to run a logistic regression, comparing low scores to high scores.\n",
        "\n",
        "After filtering out unusable rows, *ProPublica*'s next step was whether there is a significant difference in Compas scores between races. They explored this question by changing some variables into factors, and running a logistic regression, comparing low scores to high scores.\n",
        "\n",
        "These factor conversions were necessary because of RStudio syntax. The first step would be to convert the `c_charge_degree`, `age_cat`, `race`, `sex` (which are all categorical data) into factors. \n",
        "\n",
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "JMLy8BFouMQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# filter dataframe\n",
        "df <- mutate(df, crime_factor = factor(c_charge_degree)) %>%\n",
        "      mutate(age_factor = as.factor(age_cat)) %>%\n",
        "      within(age_factor <- relevel(age_factor, ref = 1)) %>%\n",
        "      mutate(race_factor = factor(race)) %>%\n",
        "      within(race_factor <- relevel(race_factor, ref = 3)) %>%\n",
        "      mutate(gender_factor = factor(sex, labels= c(\"Female\",\"Male\"))) %>%\n",
        "      within(gender_factor <- relevel(gender_factor, ref = 2)) %>%\n",
        "      mutate(score_factor = factor(score_text != \"Low\", labels = c(\"LowScore\",\"HighScore\")))\n",
        "model <- glm(score_factor ~ gender_factor + age_factor + race_factor +\n",
        "                            priors_count + crime_factor + two_year_recid, family=\"binomial\", data=df)\n",
        "\n",
        "# show updated dataframe\n",
        "summary(model)"
      ],
      "metadata": {
        "id": "eTnMDR_iuNSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But we can use the Patsy API, part of the Python `statsmodels` library, to embed these transformations within the forumla.\n",
        "\n",
        "**Python Statsmodels Syntax**\n"
      ],
      "metadata": {
        "id": "dtXCUC2MuOUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install statsmodels library\n",
        "import sys\n",
        "!{sys.executable} -m pip install statsmodels"
      ],
      "metadata": {
        "id": "ioKO8-fBuPRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load all the things\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "nPVA2YbsuQK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a score variable where \"Low\" => 0, \"Medium\"/\"High\" => 1\n",
        "filterData['score'] = (filterData['score_text'] != \"Low\") * 1"
      ],
      "metadata": {
        "id": "pE-pMZUWuRec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the Patsy API for formula generation\n",
        "formula = \"score ~ C(sex, Treatment('Male')) + age_cat + \" + \\\n",
        "          \"C(race, Treatment('Caucasian')) + priors_count + \" + \\\n",
        "          \"c_charge_degree + two_year_recid\""
      ],
      "metadata": {
        "id": "fQtXtY_yuSQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the model\n",
        "model = smf.glm(formula=formula, data=filterData, family=sm.families.Binomial()).fit()\n",
        "\n",
        "# show model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "r8-MVtF7uTiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This analysis found Black defendants are 45% more likely than white defendants to receive a higher score correcting for the seriousness of their crime, previous arrests, and future criminal behavior."
      ],
      "metadata": {
        "id": "YdMs0XZMuVDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# control calculations by race\n",
        "control <- exp(-1.52554) / (1 + exp(-1.52554))\n",
        "exp(0.47721) / (1 - control + (control * exp(0.47721)))"
      ],
      "metadata": {
        "id": "v0RejnuPuWx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Women are 19.4% more likely than men to get a higher score."
      ],
      "metadata": {
        "id": "iJlnY9XwuXaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# control calculations by gender\n",
        "exp(0.22127) / (1 - control + (control * exp(0.22127)))"
      ],
      "metadata": {
        "id": "AOlNo_mFuYo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most surprisingly, people under 25 are 2.5 times as likely to get a higher score as middle aged defendants."
      ],
      "metadata": {
        "id": "si5aK5sLuZ8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# control calculations by age\n",
        "exp(1.30839) / (1 - control + (control * exp(1.30839)))"
      ],
      "metadata": {
        "id": "vE3VVhpcuem9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Risk of Violent Recidivism\n",
        "\n",
        "COMPAS also offers a score that aims to measure a persons risk of violent recidivism, which has a similar overall accuracy to the Recidivism score. The *ProPublica* team used a logistic regression with the `compas-scores-two-years-violent` dataset to test for racial bias in the violent recidivism score.\n",
        "\n",
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "5yJfy-Bouf41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# load data from CSV file\n",
        "# compas_two_year_scores_violent <- read.csv(\"compas-scores-two-years-violent.csv\")\n",
        "\n",
        "# load data from URL\n",
        "compas_two_year_scores_violent <- read.csv(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/compas-scores-two-years-violent.csv\")\n",
        "\n",
        "# show data dimensions\n",
        "nrow(compas_two_year_scores_violent)"
      ],
      "metadata": {
        "id": "JU_kp_RcuhD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python Pandas Syntax**"
      ],
      "metadata": {
        "id": "hu5tj_OfuiSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data from file\n",
        "# compas_two_year_scores_violent = pd.read_csv('compas-scores-two-years-violent.csv', index_col=0)\n",
        "\n",
        "# load data from url\n",
        "compas_two_year_scores_violent = pd.read_csv(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/compas-scores-two-years-violent.csv\", index_col = 0)\n",
        "\n",
        "# show data shape\n",
        "compas_two_year_scores_violent.shape"
      ],
      "metadata": {
        "id": "agZlNvrUujFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the first five rows of the dataset\n",
        "pd.options.display.max_columns = None # have to do this otherwise it limits the number of cols shown\n",
        "\n",
        "# show first five rows\n",
        "compas_two_year_scores_violent.head()"
      ],
      "metadata": {
        "id": "hXABoAveukM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we can see that we have 52 columns/fields, and 7,214 rows/records in this dataset. As before, the *ProPublica* team determined a number of criteria for removing missing or unusable data. \n",
        "\n",
        "These criteria are listed below:\n",
        "- If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
        "- We coded the recidivist flag -- `is_recid` -- to be -1 if we could not find a compas case at all.\n",
        "- In a similar vein, ordinary traffic offenses -- those with a `c_charge_degree` of 'O' -- will not result in Jail time are removed (only two of them).\n",
        "- We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\n",
        "\n",
        "To filter the data using these criteria:\n",
        "\n",
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "SmRXcESpulsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# filter dataframe\n",
        "df1 <- dplyr::select(compas_two_year_scores_violent, age, c_charge_degree, race, age_cat, v_score_text, sex, priors_count, \n",
        "                    days_b_screening_arrest, v_decile_score, is_recid, two_year_recid) %>% \n",
        "        filter(days_b_screening_arrest <= 30) %>%\n",
        "        filter(days_b_screening_arrest >= -30) %>% \n",
        "        filter(is_recid != -1) %>%\n",
        "        filter(c_charge_degree != \"O\") %>%\n",
        "        filter(v_score_text != 'N/A')\n",
        "\n",
        "# show updated dataframe\n",
        "nrow(df1)"
      ],
      "metadata": {
        "id": "bHSE724-u5MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python Pandas Syntax**\n",
        "\n",
        "To be able to run a similar program in Python, we need to load the `truth_tables.py` file with named functions created by the *ProPublica* team.\n",
        "- [Link to download](https://drive.google.com/file/d/1hH8TfJ1ADcXs7WnrVrzTNPzaoGxeN4qH/view?usp=sharing) from Google Drive\n",
        "- [Link to download from GitHub](https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/truth_tables.py)\n",
        "\n",
        "If working with Jupyter Notebooks on your local computer, you'll need to move the `truth_tables.py` file into the same directory (folder) as the Jupyter Notebook.\n",
        "- Alternatively, you can provide the full file path.\n",
        "\n",
        "If working in Google CoLab, you'll either need to upload the file to your session or mount Google Drive to access the file.\n",
        "- [Uploading files](https://youtu.be/6HFlwqK3oeo?t=177)\n",
        "- [Mounting Google Drive](https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/)\n",
        "\n",
        "Alternatively, you can run the code below to download the file to your working directory.\n"
      ],
      "metadata": {
        "id": "4pL4QgpDu60u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to download the file within your Python IDE\n",
        "import json, requests, urllib, urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/truth_tables.py\", \"truth_tables.py\")"
      ],
      "metadata": {
        "id": "-v7AkZJYu8Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also need to have the `cox-violent-parsed.csv` file in your local working directory. The steps above also work, but the code below will download the file programmatically.\n",
        "- File download options\n",
        "  * [Google Drive](https://drive.google.com/file/d/1ewAjZObRNCcx55w6Z4WtbphlIRZdy_X3/view?usp=sharing)\n",
        "  * [GitHub URL](https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-violent-parsed.csv)"
      ],
      "metadata": {
        "id": "Jgvf74k0u9yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, requests, urllib, urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-violent-parsed.csv\", \"cox-violent-parsed.csv\")"
      ],
      "metadata": {
        "id": "e2GSBVazu-0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we can import functions from this file using `from truth_tables import...`."
      ],
      "metadata": {
        "id": "EeljKFC-u_cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import functions from truth tables\n",
        "from truth_tables import PeekyReader, Person, table, is_race, count, vtable, hightable, vhightable\n",
        "\n",
        "# import CSV module\n",
        "from csv import DictReader\n",
        "\n",
        "# create empty dictionary\n",
        "vpeople = []\n",
        "\n",
        "# load data\n",
        "with open(\"cox-violent-parsed.csv\") as f:\n",
        "    reader = PeekyReader(DictReader(f))\n",
        "    try:\n",
        "        while True:\n",
        "            p = Person(reader)\n",
        "            if p.valid:\n",
        "                vpeople.append(p)\n",
        "    except StopIteration:\n",
        "        pass\n",
        "\n",
        "# filter for specific condtiions\n",
        "vpop = list(filter(lambda i: ((i.violent_recidivist == True and i.lifetime <= 730) or\n",
        "                              i.lifetime > 730), list(filter(lambda x: x.vscore_valid, vpeople))))\n",
        "\n",
        "# filter for specific conditions\n",
        "vrecid = list(filter(lambda i: i.violent_recidivist == True and i.lifetime <= 730, vpeople))\n",
        "\n",
        "# create dataset with filtered results\n",
        "vrset = set(vrecid)\n",
        "vsurv = [i for i in vpop if i not in vrset]"
      ],
      "metadata": {
        "id": "A9XaqDlDvCVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show updated data\n",
        "print(\"All defendants\")\n",
        "vtable(list(vrecid), list(vsurv))"
      ],
      "metadata": {
        "id": "naVKq0TavDi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *ProPublica* team found these trends were further exacerbated for Black defendants."
      ],
      "metadata": {
        "id": "3nMI4yI-vEMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show table with violent risk scores for Black defendants\n",
        "print(\"Black defendants\")\n",
        "is_afam = is_race(\"African-American\")\n",
        "vtable(list(filter(is_afam, vrecid)), list(filter(is_afam, vsurv)))"
      ],
      "metadata": {
        "id": "0_aOkcbFvHZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show table with violent risk scores for white defendants\n",
        "print(\"White defendants\")\n",
        "is_white = is_race(\"Caucasian\")\n",
        "vtable(list(filter(is_white, vrecid)), list(filter(is_white, vsurv)))"
      ],
      "metadata": {
        "id": "-C9fdB_-vIbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *ProPublica* team found that Black defendants were twice as likely to be false positives for a Higher violent score than white defendants."
      ],
      "metadata": {
        "id": "LJihjskMvJEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "38.14 / 18.46"
      ],
      "metadata": {
        "id": "0_EvG7xrvJ6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "They also found white defendants were 63% more likely to get a lower score and commit another crime than Black defendants."
      ],
      "metadata": {
        "id": "ZN2mCcE0vKrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "62.62 / 38.37"
      ],
      "metadata": {
        "id": "nkD-ztcgvLZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Factors"
      ],
      "metadata": {
        "id": "_x6o7PIGvMUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# age distribution\n",
        "summary(df1$age_cat)"
      ],
      "metadata": {
        "id": "8u70ebV7vNCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# race/ethnicity distribution\n",
        "summary(df1$race)"
      ],
      "metadata": {
        "id": "ZCwN4W9_vN6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# number of rows where two_year_recid = 1\n",
        "nrow(filter(df1, two_year_recid == 1))"
      ],
      "metadata": {
        "id": "2gRawXkTvO0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# percentage of rows where two_year_recid = 1\n",
        "nrow(filter(df1, two_year_recid == 1)) / nrow(df) * 100"
      ],
      "metadata": {
        "id": "q2MWQxAUvP7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*ProPublica*'s analysis found a clear downward trend in the violent decile scores as those scores increase for white defendants."
      ],
      "metadata": {
        "id": "cLv5bIaZvQoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# create bar chart with decile violent risk scores for Black defendants\n",
        "pblack_v <- ggplot(data=filter(df1, race ==\"African-American\"), aes(ordered(v_decile_score))) + \n",
        "          geom_bar() + xlab(\"Violent Decile Score\") +\n",
        "          ylim(0, 650) + ggtitle(\"Black Defendant's Violent Decile Scores\")\n",
        "\n",
        "# create bar chart with decile risk scores for white defendants\n",
        "pwhite_v <- ggplot(data=filter(df1, race ==\"Caucasian\"), aes(ordered(v_decile_score))) + \n",
        "          geom_bar() + xlab(\"Violent Decile Score\") +\n",
        "          ylim(0, 650) + ggtitle(\"White Defendant's Violent Decile Scores\")\n",
        "\n",
        "# show first bar chart\n",
        "show(pblack_v)\n",
        "\n",
        "# show second bar chart\n",
        "show(pwhite_v)"
      ],
      "metadata": {
        "id": "G_IKDmtpvSOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, the *ProPublica* team explored the question of racial bias by changing some variables into factors, and running a logistic regression, comparing low scores to high scores."
      ],
      "metadata": {
        "id": "8D8-UYKGvTAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# filter data\n",
        "df1 <- mutate(df1, crime_factor = factor(c_charge_degree)) %>%\n",
        "      mutate(age_factor = as.factor(age_cat)) %>%\n",
        "      within(age_factor <- relevel(age_factor, ref = 1)) %>%\n",
        "      mutate(race_factor = factor(race,\n",
        "                                  labels = c(\"African-American\", \n",
        "                                             \"Asian\",\n",
        "                                             \"Caucasian\", \n",
        "                                             \"Hispanic\", \n",
        "                                             \"Native American\",\n",
        "                                             \"Other\"))) %>%\n",
        "      within(race_factor <- relevel(race_factor, ref = 3)) %>%\n",
        "      mutate(gender_factor = factor(sex, labels= c(\"Female\",\"Male\"))) %>%\n",
        "      within(gender_factor <- relevel(gender_factor, ref = 2)) %>%\n",
        "      mutate(score_factor = factor(v_score_text != \"Low\", labels = c(\"LowScore\",\"HighScore\")))\n",
        "model <- glm(score_factor ~ gender_factor + age_factor + race_factor +\n",
        "                            priors_count + crime_factor + two_year_recid, family=\"binomial\", data=df)\n",
        "\n",
        "# show model summary\n",
        "summary(model)"
      ],
      "metadata": {
        "id": "NCRvwGdAvUN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The violent score overpredicts recidivism for Black defendants by 77.3% compared to white defendants."
      ],
      "metadata": {
        "id": "sQ_lNm4nvVLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# control calculations by race\n",
        "control <- exp(-2.24274) / (1 + exp(-2.24274))\n",
        "exp(0.65893) / (1 - control + (control * exp(0.65893)))"
      ],
      "metadata": {
        "id": "cYdEpsNavWyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defendands under 25 are 7.4 times as likely to get a higher score as middle aged defendants."
      ],
      "metadata": {
        "id": "7EHM6-LWvXet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# control calculations by age\n",
        "exp(3.14591) / (1 - control + (control * exp(3.14591)))"
      ],
      "metadata": {
        "id": "9gxLObHfvYXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5CgSL5YySoL"
      },
      "source": [
        "## Predictive Accuracy of COMPAS\n",
        "\n",
        "To test whether Compas scores do an accurate job of deciding whether an offender is Low, Medium or High risk,  *ProPublica* ran a Cox Proportional Hazards model. Northpointe, the company that created COMPAS and markets it to Law Enforcement, also ran a Cox model in their [validation study](http://cjb.sagepub.com/content/36/1/21.abstract).\n",
        "\n",
        "*ProPublica* used the counting model and removed people when they were incarcerated. Due to errors in the underlying jail data, they ended up filtering out 32 rows that have an end date more than the start date. They determined that since there are 13,334 total rows in the data, such a small amount of errors would not affect the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhBSlNzWyUJu"
      },
      "source": [
        "### Proportional Hazards Model\n",
        "\n",
        "What is a Cox Proportional Hazards model?\n",
        "- \"**Survival analysis** is a branch of statistics for analyzing the expected duration of time until one or more events happen, such as death in biological organisms and failure in mechanical systems. This topic is called reliability theory or reliability analysis in engineering, duration analysis or duration modelling in economics, and event history analysis in sociology. Survival analysis attempts to answer certain questions, such as what is the proportion of a population which will survive past a certain time? Of those that survive, at what rate will they die or fail? Can multiple causes of death or failure be taken into account? How do particular circumstances or characteristics increase or decrease the probability of survival?\" ([Wikipedia](https://en.wikipedia.org/wiki/Survival_analysis))\n",
        "\n",
        "- \"**Proportional hazards models** are a class of survival models in statistics. Survival models relate the time that passes, before some event occurs, to one or more covariates that may be associated with that quantity of time. In a proportional hazards model, the unique effect of a unit increase in a covariate is multiplicative with respect to the hazard rate. For example, taking a drug may halve one's hazard rate for a stroke occurring, or, changing the material from which a manufactured component is constructed may double its hazard rate for failure\" ([Wikipedia](https://en.wikipedia.org/wiki/Proportional_hazards_model)).\n",
        "\n",
        "The Cox Proportional Hazards model was developed by British statistician Sir David Cox in the 1970s. \n",
        "- For more background on the model: D.R. Cox, \"[Regression Models and Life Tables]( http://www.jstor.org.proxy.library.nd.edu?url=https://www.jstor.org/stable/2985181)\" *Journal of the Royal Statistical Society* 34:2 (1972): 187-220.\n",
        "\n",
        "The model is as regression model most often used to determine the association or relationship between patient survival time and predictor variables.\n",
        "- [For more information on the underlying math in the Cox model](https://en.wikipedia.org/wiki/Proportional_hazards_model#The_Cox_model)\n",
        "- [Examples of the Cox model used to analyze health outcomes](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Survival/BS704_Survival6.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLlADsFIyWNW"
      },
      "source": [
        "### Running the Model\n",
        "\n",
        "To run this model, we need a couple of additional R packages.\n",
        "- The `ggfortify` package takes a curve and points object and converts it to a data frame that can be plotted using `ggplot2`. [For more on `ggfortify`](https://cran.r-project.org/web/packages/ggfortify/index.html)\n",
        "\n",
        "- The `survival` package contains the definition for the Cox model (as well as other statistical models). [For more on `survival`](https://cran.r-project.org/web/packages/survival/index.html)\n",
        "\n",
        "**RStudio Syntax**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# install packages\n",
        "install.packages('ggfortify')\n",
        "install.packages('survival')"
      ],
      "metadata": {
        "id": "04f8NOMT6afT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9THRdWUyXPf"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# load packages\n",
        "library(survival)\n",
        "library(ggfortify)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M8mmjl7yYdr"
      },
      "source": [
        "We also need to load data structured for the model. We can see this data has 13,419 observations.\n",
        "\n",
        "**RStudio Syntax**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWhKxUhhyaf-"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# load data from CSV file\n",
        "# cox_parsed <- read.csv(\"cox-parsed.csv\")\n",
        "\n",
        "# load data from URL\n",
        "cox_parsed <- read.csv(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-parsed.csv\")\n",
        "\n",
        "# show data dimensions\n",
        "nrow(cox_parsed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtPdd9CKyc_E"
      },
      "source": [
        "**Python Pandas Syntax**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdtEM4w_yep0"
      },
      "outputs": [],
      "source": [
        "# load data from file\n",
        "# cox_parsed = pd.read_csv('cox-parsed.csv', index_col=0)\n",
        "\n",
        "# load data from url\n",
        "cox_parsed = pd.read_csv(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-parsed.csv\", index_col = 0)\n",
        "\n",
        "# show data shape\n",
        "cox_parsed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Cvb1ZFyfmo"
      },
      "outputs": [],
      "source": [
        "# load data from url\n",
        "cox_parsed = pd.read_csv(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-parsed.csv\", index_col = 0)\n",
        "\n",
        "# show data shape\n",
        "cox_parsed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO-SGYhkyg0K"
      },
      "outputs": [],
      "source": [
        "# look at the first five rows of the dataset\n",
        "pd.options.display.max_columns = None # have to do this otherwise it limits the number of cols shown\n",
        "\n",
        "# show first five rows\n",
        "cox_parsed.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y0R2j9fyiKB"
      },
      "source": [
        "The next step taken by the ProPublica team was filtering the data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK9_W34KyjbD"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# filter data\n",
        "cox_parsed <- filter(filter(read.csv(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-parsed.csv\"), score_text != \"N/A\"), end > start) %>%\n",
        "        mutate(race_factor = factor(race,\n",
        "                                  labels = c(\"African-American\", \n",
        "                                             \"Asian\",\n",
        "                                             \"Caucasian\", \n",
        "                                             \"Hispanic\", \n",
        "                                             \"Native American\",\n",
        "                                             \"Other\"))) %>%\n",
        "        within(race_factor <- relevel(race_factor, ref = 3)) %>%\n",
        "        mutate(score_factor = factor(score_text)) %>%\n",
        "        within(score_factor <- relevel(score_factor, ref=2))\n",
        "\n",
        "# remove duplicate rows\n",
        "grp <- cox_parsed[!duplicated(cox_parsed$id),]\n",
        "\n",
        "# show updated data\n",
        "nrow(grp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKh65X7RykNC"
      },
      "source": [
        "The results of that filtering is 10,314 observations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiBqMEnXylGF"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# score ranges\n",
        "summary(grp$score_factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiTprjmIymO1"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# data summary by race/ethnicity\n",
        "summary(grp$race_factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKTrTL0hynK3"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# score factor\n",
        "f <- Surv(start, end, event, type=\"counting\") ~ score_factor\n",
        "\n",
        "# create model\n",
        "model <- coxph(f, data=cox_parsed)\n",
        "\n",
        "# model summary\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnvGCkt9ynwn"
      },
      "source": [
        "People placed in the `High` category are 3.5 times as likely to recidivate, and the COMPAS system's concordance 63.6%. This is lower than the accuracy quoted in the Northpoint study of 68%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UkJJ-Cwyo3_"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# decile scores\n",
        "decile_f <- Surv(start, end, event, type=\"counting\") ~ decile_score\n",
        "\n",
        "# create decile score model\n",
        "dmodel <- coxph(decile_f, data=cox_parsed)\n",
        "\n",
        "# show decile score model\n",
        "summary(dmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHLIb8fOyp4d"
      },
      "source": [
        "COMPAS's decile scores are a bit more accurate at 66%.\n",
        "\n",
        "*ProPublica* tested if the algorithm behaved differently across races by including a race interaction term in the cox model.\n",
        "\n",
        "**RStudio Syntax**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwLrR2nVyq34"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# score factor\n",
        "f2 <- Surv(start, end, event, type=\"counting\") ~ race_factor + score_factor + race_factor * score_factor\n",
        "\n",
        "# create model\n",
        "model <- coxph(f2, data=cox_parsed)\n",
        "\n",
        "# show model summary\n",
        "print(summary(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN-xoW0myr5C"
      },
      "source": [
        "\n",
        "The *ProPublica* team found that the interaction term shows a similar disparity as the logistic regression above. They also found high risk white defendants are 3.61 more likely than low risk white defendants, while High risk Black defendants are 2.99 more likely than low.\n",
        "\n",
        "\n",
        "**Python Math Syntax**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUt6wc61ytBp"
      },
      "outputs": [],
      "source": [
        "# import statement\n",
        "import math\n",
        "\n",
        "# show interaction term by race\n",
        "print(\"Black High Hazard: %.2f\" % (math.exp(-0.18976 + 1.28350)))\n",
        "print(\"White High Hazard: %.2f\" % (math.exp(1.28350)))\n",
        "print(\"Black Medium Hazard: %.2f\" % (math.exp(0.84286-0.17261)))\n",
        "print(\"White Medium Hazard: %.2f\" % (math.exp(0.84286)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "QkC1XmJlv_iB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TceccSWMyuH-"
      },
      "outputs": [],
      "source": [
        "%%R -w 900 -h 563 -u px\n",
        "# create fitted curve based on survival model\n",
        "fit <- survfit(f, data=cox_parsed)\n",
        "\n",
        "# plot curve\n",
        "plotty <- function(fit, title) {\n",
        "  return(autoplot(fit, conf.int=T, censor=F) + ggtitle(title) + ylim(0,1))\n",
        "}\n",
        "\n",
        "# show plot\n",
        "plotty(fit, \"Overall\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJQP4T8AyvMj"
      },
      "source": [
        "The *ProPublica* team found that Black defendants do recidivate at higher rates according to race specific Kaplan Meier plots.\n",
        "\n",
        "**RStudio Syntax**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob5P3OfRywFL"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# filter data for white defendants\n",
        "white <- filter(cox_parsed, race == \"Caucasian\")\n",
        "white_fit <- survfit(f, data=white)\n",
        "\n",
        "# filter data for Black defendants\n",
        "black <- filter(cox_parsed, race == \"African-American\")\n",
        "black_fit <- survfit(f, data=black)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGGJJpJsyxF8"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# plot white defendants\n",
        "plotty(white_fit, \"White defendants\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Fcocp2lyyA1"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# plot Black defendants\n",
        "plotty(black_fit, \"Black defendants\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__vq5ov3yy6O"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# calculate model summary\n",
        "summary(fit, times=c(730))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_A6t2Lkyzz1"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# calculate model summary for Black defendants\n",
        "summary(black_fit, times=c(730))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy3tpd3Zy0_D"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# calculate model summary for white defendnats\n",
        "summary(white_fit, times=c(730))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE-jlQpjy13B"
      },
      "source": [
        "The *ProPublica* team found that race specific models had similar concordance values.\n",
        "\n",
        "**RStudio Syntax**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NQHQ5gDy22H"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# calculate concordance values for white defendnats\n",
        "summary(coxph(f, data=white))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tJWzIqWy36M"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# calculate concordance values for Black defendants\n",
        "summary(coxph(f, data=black))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMEDNQNcy4nl"
      },
      "source": [
        "The *ProPublica* team found that Compas's violent recidivism score has a slightly higher overall concordance score of 65.1%.\n",
        "\n",
        "**RStudio Syntax**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdncb-R-zD_G"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# load and filter data\n",
        "violent_data <- filter(filter(read.csv(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-violent-parsed.csv\"), score_text != \"N/A\"), end > start) %>%\n",
        "        mutate(race_factor = factor(race,\n",
        "                                  labels = c(\"African-American\", \n",
        "                                             \"Asian\",\n",
        "                                             \"Caucasian\", \n",
        "                                             \"Hispanic\", \n",
        "                                             \"Native American\",\n",
        "                                             \"Other\"))) %>%\n",
        "        within(race_factor <- relevel(race_factor, ref = 3)) %>%\n",
        "        mutate(score_factor = factor(score_text)) %>%\n",
        "        within(score_factor <- relevel(score_factor, ref=2))\n",
        "\n",
        "\n",
        "# create survival model\n",
        "vf <- Surv(start, end, event, type=\"counting\") ~ score_factor\n",
        "\n",
        "# create concordance values\n",
        "vmodel <- coxph(vf, data=violent_data)\n",
        "\n",
        "# remove duplicates\n",
        "vgrp <- violent_data[!duplicated(violent_data$id),]\n",
        "\n",
        "# print output\n",
        "print(nrow(vgrp))\n",
        "\n",
        "# model summary\n",
        "summary(vmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOOEgi0JzFH3"
      },
      "source": [
        "The *ProPublica* team found that in this case, there isn't a significant coefficient on Black/African American defendants with High Scores.\n",
        "\n",
        "**RStudio Syntax**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irw-KCTszGFI"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# survival model\n",
        "vf2 <- Surv(start, end, event, type=\"counting\") ~ race_factor + race_factor * score_factor\n",
        "\n",
        "# concordance values\n",
        "vmodel <- coxph(vf2, data=violent_data)\n",
        "\n",
        "# model summary \n",
        "summary(vmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63ECDNq4zG9d"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# concordance values summary for Black defendants\n",
        "summary(coxph(vf, data=filter(violent_data, race == \"African-American\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvj0JZPHzI-j"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# concordance values summary for white defendants\n",
        "summary(coxph(vf, data=filter(violent_data, race == \"Caucasian\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GIgMgXOzKBI"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# filter data for white defendnats\n",
        "white <- filter(violent_data, race == \"Caucasian\")\n",
        "\n",
        "# create survival model for white defendants\n",
        "white_fit <- survfit(vf, data=white)\n",
        "\n",
        "# filter data for black defendants\n",
        "black <- filter(violent_data, race == \"African-American\")\n",
        "\n",
        "# create survival model for black defendants\n",
        "black_fit <- survfit(vf, data=black)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG3rDdznzLHC"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# plot white defendants\n",
        "plotty(white_fit, \"White defendants\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5bNzCjTzQHg"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# plot Black defendants\n",
        "plotty(black_fit, \"Black defendants\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DASui6UVzR9Y"
      },
      "source": [
        "## Directions of the Racial Bias\n",
        "\n",
        "*ProPublica*'s analysis found that the COMPAS algorithm does overpredict Black defendant's future recidivism. The next section of the lab looks at how they explored the direction of the bias. Their analysis found fine differences in overprediction and underprediction by comparing COMPAS scores across racial lines.\n",
        "\n",
        "To be able to run a similar program in Python, we need to load the `truth_tables.py` file with named functions created by the *ProPublica* team.\n",
        "- [Link to download](https://drive.google.com/file/d/1hH8TfJ1ADcXs7WnrVrzTNPzaoGxeN4qH/view?usp=sharing) from Google Drive\n",
        "- [Link to download from GitHub](https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/truth_tables.py)\n",
        "\n",
        "If working with Jupyter Notebooks on your local computer, you'll need to move the `truth_tables.py` file into the same directory (folder) as the Jupyter Notebook.\n",
        "- Alternatively, you can provide the full file path.\n",
        "\n",
        "If working in Google CoLab, you'll either need to upload the file to your session or mount Google Drive to access the file.\n",
        "- [Uploading files](https://youtu.be/6HFlwqK3oeo?t=177)\n",
        "- [Mounting Google Drive](https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/)\n",
        "\n",
        "Alternatively, you can run the code below to download the file to your working directory."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code to download the file within your Python IDE\n",
        "import json, requests, urllib, urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/truth_tables.py\", \"truth_tables.py\")"
      ],
      "metadata": {
        "id": "zfmrF9hvwuux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also need to have the `cox-violent-parsed.csv` file in your local working directory. The steps above also work, but the code below will download the file programmatically.\n",
        "- File download options\n",
        "  * [Google Drive](https://drive.google.com/file/d/1uGr-5xnRPdcZKHtgCY6qiSDguPjNLzoL/view?usp=sharing)\n",
        "  * [GitHub URL](https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-parsed.csv)"
      ],
      "metadata": {
        "id": "kj37jfsTwtdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to download the cox-parsed.csv within your Python IDE\n",
        "import json, requests, urllib, urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kwaldenphd/propublica-compas-lab/main/data/cox-parsed.csv\", \"cox-violent-parsed.csv\")"
      ],
      "metadata": {
        "id": "2E7SPdVswwTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we can import functions from this file using `from truth_tables import...`.\n",
        "\n",
        "**Python Syntax**"
      ],
      "metadata": {
        "id": "ikqymMpFwxwa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMABb1jOzU7L"
      },
      "outputs": [],
      "source": [
        "# import functions from truth tables\n",
        "from truth_tables import PeekyReader, Person, table, is_race, count, vtable, hightable, vhightable\n",
        "\n",
        "# import CSV module\n",
        "from csv import DictReader\n",
        "\n",
        "# create empty dictionary\n",
        "people = []\n",
        "\n",
        "# load parsed data\n",
        "with open(\"cox-parsed.csv\") as f:\n",
        "    reader = PeekyReader(DictReader(f))\n",
        "    try:\n",
        "        while True:\n",
        "            p = Person(reader)\n",
        "            if p.valid:\n",
        "                people.append(p)\n",
        "    except StopIteration:\n",
        "        pass\n",
        "\n",
        "# filter for specific conditions\n",
        "pop = list(filter(lambda i: ((i.recidivist == True and i.lifetime <= 730) or\n",
        "                              i.lifetime > 730), list(filter(lambda x: x.score_valid, people))))\n",
        "\n",
        "# filter for specific fonditions\n",
        "recid = list(filter(lambda i: i.recidivist == True and i.lifetime <= 730, pop))\n",
        "\n",
        "rset = set(recid)\n",
        "\n",
        "# show survival score\n",
        "surv = [i for i in pop if i not in rset]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print table risk scores\n",
        "with print(\"All defendants\")\n",
        "table(list(recid), list(surv))"
      ],
      "metadata": {
        "id": "VLx6WwRI8YG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print percentage of total population\n",
        "print(\"Total pop: %i\" % (2681 + 1282 + 1216 + 2035))"
      ],
      "metadata": {
        "id": "SUpmyXAf8ZJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import statistics module\n",
        "import statistics\n",
        "\n",
        "# print followup time\n",
        "print(\"Average followup time %.2f (sd %.2f)\" % (statistics.mean(map(lambda i: i.lifetime, pop)),\n",
        "                                                statistics.stdev(map(lambda i: i.lifetime, pop))))\n",
        "\n",
        "# print median followup time\n",
        "print(\"Median followup time %i\" % (statistics.median(map(lambda i: i.lifetime, pop))))"
      ],
      "metadata": {
        "id": "0NTT6xek8afg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the false positive rate is 32.35%."
      ],
      "metadata": {
        "id": "Fpnu72sJ8elq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create table with risk scores for Black defendants\n",
        "print(\"Black defendants\")\n",
        "is_afam = is_race(\"African-American\")\n",
        "table(list(filter(is_afam, recid)), list(filter(is_afam, surv)))"
      ],
      "metadata": {
        "id": "4LoPR3TY8bi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That number is higher for Black defendants at 44.85%.\n",
        "\n"
      ],
      "metadata": {
        "id": "bl-yKGNo8f4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create table with risk scores for white defendants\n",
        "print(\"White defendants\")\n",
        "is_white = is_race(\"Caucasian\")\n",
        "table(list(filter(is_white, recid)), list(filter(is_white, surv)))"
      ],
      "metadata": {
        "id": "7sYTKWfo8dHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And lower for white defendants at 23.45%.\n",
        "\n"
      ],
      "metadata": {
        "id": "GuiLy3cl8izX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "44.85 / 23.45"
      ],
      "metadata": {
        "id": "-VMjCsBw8jqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the *ProPublica* team's analysis, these results mean under COMPAS Black defendants are 91% more likely to get a higher score and not go on to commit more crimes than white defendants after two years.\n",
        "\n",
        "They also found that COMPAS scores misclassify white reoffenders as low risk at 70.4% more often than Black reoffenders.\n",
        "\n",
        "**Python Syntax**"
      ],
      "metadata": {
        "id": "k5fqMtGx8lJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "47.72 / 27.99"
      ],
      "metadata": {
        "id": "jg_g1GEg8l_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create table for white defendants' risk scores\n",
        "hightable(list(filter(is_white, recid)), list(filter(is_white, surv)))"
      ],
      "metadata": {
        "id": "bC17WxRS8nIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create table for Black defendants' risk scores\n",
        "hightable(list(filter(is_afam, recid)), list(filter(is_afam, surv)))"
      ],
      "metadata": {
        "id": "DEP-gqhf8oPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gender Differences in COMPAS Scores\n",
        "\n",
        "The *ProPublica* team used gender-specific Kaplan Meier estimates to look at differences between men and women in terms of underlying recidivism rates.\n",
        "\n",
        "**RStudio Syntax**"
      ],
      "metadata": {
        "id": "aHKIWewb8pl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# filter by gender\n",
        "female <- filter(cox_parsed, sex == \"Female\")\n",
        "male   <- filter(cox_parsed, sex == \"Male\")\n",
        "male_fit <- survfit(f, data=male)\n",
        "female_fit <- survfit(f, data=female)"
      ],
      "metadata": {
        "id": "2fwgaDW58qxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# show summary for male defendants\n",
        "summary(male_fit, times=c(730))"
      ],
      "metadata": {
        "id": "L5DhiMHR8r1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# show summary for female defendants\n",
        "summary(female_fit, times=c(730))"
      ],
      "metadata": {
        "id": "-EBAJ84a8s1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "# plot female defendants\n",
        "plotty(female_fit, \"Female\")"
      ],
      "metadata": {
        "id": "xjkCL13M8t09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "# plot male defendants\n",
        "plotty(male_fit, \"Male\")"
      ],
      "metadata": {
        "id": "SIbiSzHK8u6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From these plots, the *ProPublica* team determined the Compas score treats a `High risk woman` the same as a `Medium risk man`.\n",
        "\n",
        "# Putting It All Together\n",
        "\n",
        "Let's take a step back here and think about what these results mean, or at least what they mean in relation to the conclusions drawn in the *ProPublica* article.\n",
        "\n",
        "Discussion questions:\n",
        "- What conclusions would you draw about the COMPAS algorithm based on this analysis?\n",
        "- What other types of questions would you want to ask or what else do you want to know about the algorithm?\n",
        "- How does the analysis outlined in this lab and the ProPublica methodology white paper relate to the arguments/conclusions presented in the \"Machine Bias\" article?\n",
        "- What limitations or shortcomings would you identify for this analysis (the analysis itself, the statistical models used, the input data, etc.)?\n",
        "- Other comments, questions, observations, etc."
      ],
      "metadata": {
        "id": "RDVt_OA48wSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Critiques of the ProPublica Project\n",
        "\n",
        "There have been some critiques and responses to *ProPublica*'s methodology, specifically around the data analysis component.\n",
        "\n",
        "If you're interested in exploring these critiques:\n",
        "- Northpointe:\n",
        "  * Northpointe Suite, \"[Response to ProPublica: Demonstrating Accuracy Equity, and Predictive Parity](https://www.equivant.com/response-to-propublica-demonstrating-accuracy-equity-and-predictive-parity/)\" *Equivant blog* (8 July 2016)\n",
        "  * Northpointe Inc. Research Department, \"[Response to ProPublica: Demonstrating Accuracy Equity, and Predictive Parity](http://go.volarisgroup.com/rs/430-MBX-989/images/ProPublica_Commentary_Final_070616.pdf/)\" *Research Paper* (8 July 2016)\n",
        "\n",
        "- Llewellyn Hinkes Jones, \"[ProPublica's Misleading Machine Bias](https://medium.com/@llewhinkes/propublicas-misleading-machine-bias-19c971549a18)\" *Medium blog* (6 October 2020)\n",
        "\n",
        "- Matias Barenstein (Economist at Federal Trade Commission)\n",
        "  * [GitHub repository](https://github.com/mbarenstein/ProPublica_COMPAS_Data_Revisited)\n",
        "  * [preprint research article deposited with arXiv](https://arxiv.org/abs/1906.04711)\n",
        "  * \"[The Data Processing Error in a Prominent Fair Machine Learning Dataset](https://towardsdatascience.com/the-data-processing-error-in-the-most-prominent-fair-machine-learning-dataset-short-version-d27d8d390fea)\" *Towards Data Science* (22 August 2019)\n",
        "\n",
        "Discussion questions:\n",
        "- What are some of your initial observations or thoughts on these critiques?\n",
        "- How do these critiques respond to or engage with the ProPublica investigation?\n",
        "- What are some of your takeaways from exploring these critiques?\n",
        "- Particularly, how are you thinking about what it looks like to analyze, investigate, or hold accountable “black box” tech systems?\n",
        "- Other comments, questions, observations, etc."
      ],
      "metadata": {
        "id": "4x9sAkvV8xx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Notebook Components\n",
        "\n",
        "Lab Notebook Template:\n",
        "- [Jupyter Notebook](https://colab.research.google.com/drive/1e3ZeCyHOjauNVEW5U0NPq-_exceAKYmy?usp=sharing)\n",
        "- [Google Doc](https://docs.google.com/document/d/1SzcEiEbTTTyiPDygGP4Bw0OWOwEsN0Y5x7RHfJCP-Vw/copy)\n",
        "\n",
        "The lab notebook consists of a narrative that documents and describes your experience working through this lab.\n",
        "\n",
        "You can respond to/engage with the discussion questions embedded throughout the lab procedure.\n",
        "\n",
        "Other questions for the lab notebook: \n",
        "- What challenges did you face, and how did you solve them?\n",
        "- What did you learn about machine learning/predictive models through this lab?\n",
        "- How are you thinking about the *ProPublica* article and investigation after this lab?\n",
        "- How are you thinking about race and surveillance after this case study/lab?\n",
        "- Other comments/questions/observations\n",
        "\n",
        "I encourage folks to include code and/or screenshots as part of that narrative.\n",
        "- You are welcome (but not required) to include code as part of that narrative."
      ],
      "metadata": {
        "id": "j3v7rBXF84lR"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOUTFRWoMWeWsD1qilUgbaZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}